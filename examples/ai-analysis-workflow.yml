# AI Analysis Example
# Shows different AI provider configurations

name: E2E Tests - with AI Analysis

on:
  push:
    branches: [main]
  schedule:
    - cron: '0 0 * * *'  # Daily at midnight

jobs:
  # Option 1: OpenRouter (Recommended - Cheapest)
  test-with-openrouter:
    name: Tests with OpenRouter AI
    runs-on: ubuntu-latest
    permissions:
      issues: write

    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: '18'

      - name: Install and test
        id: playwright-tests
        run: |
          npm ci
          npx playwright install --with-deps
          set +e  # Disable exit on error to capture test exit code
          npx playwright test --reporter=json > test-results.json 2>&1
          TEST_EXIT_CODE=$?
          set -e  # Re-enable exit on error
          echo "test-failed=$([ $TEST_EXIT_CODE -ne 0 ] && echo 'true' || echo 'false')" >> $GITHUB_OUTPUT
          exit $TEST_EXIT_CODE
        continue-on-error: true

      - name: Analyze with OpenRouter + DeepSeek
        if: steps.playwright-tests.outputs.test-failed == 'true'
        uses: decision-crafters/playwright-failure-analyzer@v1
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          report-path: 'test-results.json'
          ai-analysis: true
          issue-title: 'ðŸ¤– AI-Analyzed Test Failures (DeepSeek)'
        env:
          OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
          AI_MODEL: 'openrouter/deepseek/deepseek-chat'
          # Cost: ~$0.0003 per analysis

  # Option 2: OpenAI GPT-4o-mini
  test-with-openai:
    name: Tests with OpenAI
    runs-on: ubuntu-latest
    permissions:
      issues: write

    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: '18'

      - name: Install and test
        id: playwright-tests
        run: |
          npm ci
          npx playwright install --with-deps
          set +e  # Disable exit on error to capture test exit code
          npx playwright test --reporter=json > test-results.json 2>&1
          TEST_EXIT_CODE=$?
          set -e  # Re-enable exit on error
          echo "test-failed=$([ $TEST_EXIT_CODE -ne 0 ] && echo 'true' || echo 'false')" >> $GITHUB_OUTPUT
          exit $TEST_EXIT_CODE
        continue-on-error: true

      - name: Analyze with OpenAI
        if: steps.playwright-tests.outputs.test-failed == 'true'
        uses: decision-crafters/playwright-failure-analyzer@v1
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          report-path: 'test-results.json'
          ai-analysis: true
          issue-title: 'ðŸ¤– AI-Analyzed Test Failures (GPT-4o-mini)'
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          AI_MODEL: 'gpt-4o-mini'
          # Cost: ~$0.0003 per analysis

  # Option 3: Anthropic Claude (Premium)
  test-with-claude:
    name: Tests with Claude (Premium)
    runs-on: ubuntu-latest
    permissions:
      issues: write

    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: '18'

      - name: Install and test
        id: playwright-tests
        run: |
          npm ci
          npx playwright install --with-deps
          set +e  # Disable exit on error to capture test exit code
          npx playwright test --reporter=json > test-results.json 2>&1
          TEST_EXIT_CODE=$?
          set -e  # Re-enable exit on error
          echo "test-failed=$([ $TEST_EXIT_CODE -ne 0 ] && echo 'true' || echo 'false')" >> $GITHUB_OUTPUT
          exit $TEST_EXIT_CODE
        continue-on-error: true

      - name: Analyze with Claude
        if: steps.playwright-tests.outputs.test-failed == 'true'
        uses: decision-crafters/playwright-failure-analyzer@v1
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          report-path: 'test-results.json'
          ai-analysis: true
          issue-title: 'ðŸ¤– AI-Analyzed Test Failures (Claude 3.5)'
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          AI_MODEL: 'claude-3-5-sonnet-20240620'
          # Cost: ~$0.006 per analysis (premium quality)

  # Option 4: Without AI (Fastest, Free)
  test-without-ai:
    name: Tests without AI
    runs-on: ubuntu-latest
    permissions:
      issues: write

    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: '18'

      - name: Install and test
        id: playwright-tests
        run: |
          npm ci
          npx playwright install --with-deps
          set +e  # Disable exit on error to capture test exit code
          npx playwright test --reporter=json > test-results.json 2>&1
          TEST_EXIT_CODE=$?
          set -e  # Re-enable exit on error
          echo "test-failed=$([ $TEST_EXIT_CODE -ne 0 ] && echo 'true' || echo 'false')" >> $GITHUB_OUTPUT
          exit $TEST_EXIT_CODE
        continue-on-error: true

      - name: Analyze without AI
        if: steps.playwright-tests.outputs.test-failed == 'true'
        uses: decision-crafters/playwright-failure-analyzer@v1
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          report-path: 'test-results.json'
          ai-analysis: false  # Disable AI
          issue-title: 'Test Failures (No AI Analysis)'
        # No API key needed, fastest execution, no cost
