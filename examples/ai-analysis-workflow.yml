# AI Analysis Example - v1.1.0+ Enhanced Features
# Shows different AI provider configurations with actionable insights
#
# What you get with AI Analysis (v1.1.0+):
# - ðŸŽ¯ Priority Assessment (Critical/High/Medium/Low)
# - ðŸ“‹ Recommended Work Order (what to fix first)
# - âš¡ Quick Wins (fixes under 10 minutes)
# - ðŸ”§ Specific Fix Recommendations with effort estimates
# - ðŸ“Š Failure Categories (test/app/infrastructure/flaky)
# - ðŸ’¡ Test Quality Improvements (long-term suggestions)

name: E2E Tests - with AI Analysis

on:
  push:
    branches: [main]
  schedule:
    - cron: '0 0 * * *'  # Daily at midnight

jobs:
  # Option 1: OpenRouter (Recommended - Cheapest)
  test-with-openrouter:
    name: Tests with OpenRouter AI
    runs-on: ubuntu-latest
    permissions:
      issues: write

    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: '18'

      - name: Install and test
        id: playwright-tests
        run: |
          npm ci
          npx playwright install --with-deps
          set +e  # Disable exit on error to capture test exit code
          npx playwright test --reporter=json > test-results.json 2>&1
          TEST_EXIT_CODE=$?
          set -e  # Re-enable exit on error
          echo "test-failed=$([ $TEST_EXIT_CODE -ne 0 ] && echo 'true' || echo 'false')" >> $GITHUB_OUTPUT
          exit $TEST_EXIT_CODE
        continue-on-error: true

      - name: Analyze with OpenRouter + DeepSeek
        if: steps.playwright-tests.outputs.test-failed == 'true'
        uses: decision-crafters/playwright-failure-analyzer@v1.1.0  # Enhanced AI features
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          report-path: 'test-results.json'
          ai-analysis: true
          issue-title: 'ðŸ¤– AI-Analyzed Test Failures (DeepSeek)'
        env:
          OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
          AI_MODEL: 'openrouter/deepseek/deepseek-chat'
          # Cost: ~$0.0003 per analysis
          # Creates issues with priority ranking, work order, and effort estimates

  # Option 2: OpenAI GPT-4o-mini
  test-with-openai:
    name: Tests with OpenAI
    runs-on: ubuntu-latest
    permissions:
      issues: write

    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: '18'

      - name: Install and test
        id: playwright-tests
        run: |
          npm ci
          npx playwright install --with-deps
          set +e  # Disable exit on error to capture test exit code
          npx playwright test --reporter=json > test-results.json 2>&1
          TEST_EXIT_CODE=$?
          set -e  # Re-enable exit on error
          echo "test-failed=$([ $TEST_EXIT_CODE -ne 0 ] && echo 'true' || echo 'false')" >> $GITHUB_OUTPUT
          exit $TEST_EXIT_CODE
        continue-on-error: true

      - name: Analyze with OpenAI
        if: steps.playwright-tests.outputs.test-failed == 'true'
        uses: decision-crafters/playwright-failure-analyzer@v1.1.0  # Enhanced AI features
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          report-path: 'test-results.json'
          ai-analysis: true
          issue-title: 'ðŸ¤– AI-Analyzed Test Failures (GPT-4o-mini)'
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          AI_MODEL: 'gpt-4o-mini'
          # Cost: ~$0.0003 per analysis
          # Creates issues with priority ranking, work order, and effort estimates

  # Option 3: Anthropic Claude (Premium)
  test-with-claude:
    name: Tests with Claude (Premium)
    runs-on: ubuntu-latest
    permissions:
      issues: write

    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: '18'

      - name: Install and test
        id: playwright-tests
        run: |
          npm ci
          npx playwright install --with-deps
          set +e  # Disable exit on error to capture test exit code
          npx playwright test --reporter=json > test-results.json 2>&1
          TEST_EXIT_CODE=$?
          set -e  # Re-enable exit on error
          echo "test-failed=$([ $TEST_EXIT_CODE -ne 0 ] && echo 'true' || echo 'false')" >> $GITHUB_OUTPUT
          exit $TEST_EXIT_CODE
        continue-on-error: true

      - name: Analyze with Claude
        if: steps.playwright-tests.outputs.test-failed == 'true'
        uses: decision-crafters/playwright-failure-analyzer@v1.1.0  # Enhanced AI features
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          report-path: 'test-results.json'
          ai-analysis: true
          issue-title: 'ðŸ¤– AI-Analyzed Test Failures (Claude 3.5)'
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          AI_MODEL: 'claude-3-5-sonnet-20240620'
          # Cost: ~$0.006 per analysis (premium quality)
          # Creates issues with priority ranking, work order, and effort estimates

  # Option 4: Without AI (Fastest, Free)
  test-without-ai:
    name: Tests without AI
    runs-on: ubuntu-latest
    permissions:
      issues: write

    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: '18'

      - name: Install and test
        id: playwright-tests
        run: |
          npm ci
          npx playwright install --with-deps
          set +e  # Disable exit on error to capture test exit code
          npx playwright test --reporter=json > test-results.json 2>&1
          TEST_EXIT_CODE=$?
          set -e  # Re-enable exit on error
          echo "test-failed=$([ $TEST_EXIT_CODE -ne 0 ] && echo 'true' || echo 'false')" >> $GITHUB_OUTPUT
          exit $TEST_EXIT_CODE
        continue-on-error: true

      - name: Analyze without AI
        if: steps.playwright-tests.outputs.test-failed == 'true'
        uses: decision-crafters/playwright-failure-analyzer@v1.1.0
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          report-path: 'test-results.json'
          ai-analysis: false  # Disable AI
          issue-title: 'Test Failures (No AI Analysis)'
        # No API key needed, fastest execution, no cost
        # Still includes comprehensive failure details, just without AI insights
